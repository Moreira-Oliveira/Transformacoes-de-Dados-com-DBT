# Transformacoes-de-Dados-com-DBT

# O Que Ã© TransformaÃ§Ã£o de Dados?

TransformaÃ§Ã£o de dados Ã© o processo de converter, organizar ou modificar dados de um formato bruto ou original para um formato mais adequado e Ãºtil para anÃ¡lise, armazenamento ou uso em sistemas especÃ­ficos.
Esse processo Ã© essencial na engenharia de dados, especialmente em pipelines de ETL (Extract, Transform, Load â€“ ExtraÃ§Ã£o, TransformaÃ§Ã£o e Carga) ou ELT (Extract, Load, Transform â€“ ExtraÃ§Ã£o, Carga e TransformaÃ§Ã£o).


# principais aspectos da TransformaÃ§Ã£o de Dados

ğŸ”¹ 1. Qualidade dos Dados

* CorreÃ§Ã£o de erros: como valores invÃ¡lidos, inconsistentes ou fora de padrÃ£o.

* RemoÃ§Ã£o de duplicidades: eliminar registros redundantes.

* Tratamento de dados ausentes (nulls): preenchimento, exclusÃ£o ou substituiÃ§Ã£o por valores padrÃ£o.


ğŸ”¹ 2. PadronizaÃ§Ã£o e NormalizaÃ§Ã£o

* UniformizaÃ§Ã£o de formatos: datas no mesmo padrÃ£o, textos em caixa baixa, etc.

* NormalizaÃ§Ã£o numÃ©rica: escalonamento de valores (ex: entre 0 e 1) para anÃ¡lises ou modelos.


ğŸ”¹ 3. ConversÃ£o de Tipos de Dados

* Transformar tipos como string para inteiro, data, booleano, etc., de acordo com o uso final.


ğŸ”¹ 4. AgregaÃ§Ãµes e CÃ¡lculos

* Resumos estatÃ­sticos: mÃ©dia, soma, contagem, mÃ¡ximo/mÃ­nimo.

* Colunas derivadas: novos campos criados com base em fÃ³rmulas (ex: lucro = receita - custo).


ğŸ”¹ 5. Enriquecimento de Dados

* InserÃ§Ã£o de informaÃ§Ãµes complementares, como dados geogrÃ¡ficos ou demogrÃ¡ficos, via junÃ§Ãµes com outras fontes.


ğŸ”¹ 6. Filtragem e SeleÃ§Ã£o

* Isolamento de registros relevantes com base em regras de negÃ³cio ou critÃ©rios de anÃ¡lise.


ğŸ”¹ 7. Mapeamento e SubstituiÃ§Ã£o de Valores

* Troca de cÃ³digos por descriÃ§Ãµes legÃ­veis (ex: 1 â†’ "Ativo", 0 â†’ "Inativo").

* ReclassificaÃ§Ã£o ou agrupamento de categorias.


ğŸ”¹ 8. IntegraÃ§Ã£o de Dados

* Combinar informaÃ§Ãµes de mÃºltiplas fontes (bancos de dados, planilhas, APIs, etc.) em um Ãºnico dataset coerente.


ğŸ”¹ 9. Ordem e Estrutura

* ReorganizaÃ§Ã£o das colunas ou registros conforme a necessidade (ex: ordenaÃ§Ã£o por data).

* TransformaÃ§Ãµes de formatos (ex: de JSON para tabela relacional).


ğŸ”¹ 10. AutomaÃ§Ã£o e Reprodutibilidade

* Garantir que a transformaÃ§Ã£o possa ser reproduzida automaticamente em pipelines com ferramentas como dbt, Airflow, Spark, Pandas, entre outras.


# AplicaÃ§Ãµes prÃ¡ticas


Aqui estÃ£o algumas aplicaÃ§Ãµes prÃ¡ticas da transformaÃ§Ã£o de dados em diferentes contextos do mundo real. Cada exemplo mostra como esse processo Ã© essencial para anÃ¡lise, tomada de decisÃ£o e eficiÃªncia operacional:


ğŸ“Š 1. Business Intelligence (BI)

Contexto: Uma empresa quer analisar as vendas mensais por regiÃ£o.

TransformaÃ§Ãµes realizadas:

* ConversÃ£o de datas para o formato padrÃ£o (YYYY-MM).

* JunÃ§Ã£o de tabelas de vendas com dados de regiÃµes e produtos.

* AgregaÃ§Ã£o da receita por mÃªs e por regiÃ£o.

* CriaÃ§Ã£o de uma coluna de margem de lucro (receita - custo).

Ferramentas usadas: SQL, Power BI, Tableau


ğŸ›’ 2. E-commerce

Contexto: Identificar os clientes com maior valor de compra nos Ãºltimos 6 meses.

TransformaÃ§Ãµes realizadas:

* Filtragem de transaÃ§Ãµes nos Ãºltimos 180 dias.

* ConversÃ£o de valores monetÃ¡rios para o mesmo padrÃ£o de moeda.

* Agrupamento por cliente e soma do valor gasto.

* OrdenaÃ§Ã£o e classificaÃ§Ã£o dos top clientes.

Ferramentas usadas: Python (pandas), SQL, dbt


ğŸ¥ 3. SaÃºde

Contexto: Integrar dados de pacientes vindos de diferentes hospitais.

TransformaÃ§Ãµes realizadas:

* PadronizaÃ§Ã£o de formatos de data e nomes de campos.

* NormalizaÃ§Ã£o de unidades (ex: peso em kg, temperatura em Â°C).

* Tratamento de dados ausentes e inconsistentes (ex: datas invÃ¡lidas).

* Mapeamento de cÃ³digos de doenÃ§as para descriÃ§Ãµes.

Ferramentas usadas: Spark, Apache NiFi, Python


ğŸ¦ 4. Setor Financeiro

Contexto: Calcular risco de crÃ©dito com base no histÃ³rico de transaÃ§Ãµes.

TransformaÃ§Ãµes realizadas:

* CriaÃ§Ã£o de colunas derivadas como: mÃ©dia de gastos mensais, padrÃ£o de atraso de pagamento.

* Enriquecimento com dados externos (ex: score de crÃ©dito).

* NormalizaÃ§Ã£o de dados para alimentar modelos preditivos.

Ferramentas usadas: Python, PySpark, SQL, Scikit-learn


ğŸšš 5. LogÃ­stica

Contexto: Otimizar rotas de entrega com base no histÃ³rico de atrasos.

TransformaÃ§Ãµes realizadas:

* ConversÃ£o de timestamps em tempo total de entrega.

* CÃ¡lculo da mÃ©dia e desvio padrÃ£o por rota.

* IdentificaÃ§Ã£o de padrÃµes com maior probabilidade de atraso.

* Enriquecimento com dados de trÃ¢nsito e clima.

Ferramentas usadas: Python, Pandas, GeoPandas, APIs externas


ğŸ“ 6. EducaÃ§Ã£o

Contexto: Avaliar desempenho de alunos por disciplina.

TransformaÃ§Ãµes realizadas:

* JunÃ§Ã£o de notas, frequÃªncia e atividades em uma Ãºnica tabela.

* CÃ¡lculo de mÃ©dias ponderadas por matÃ©ria.

* CategorizaÃ§Ã£o do desempenho (ex: "Excelente", "Regular", "Ruim").

* Filtragem de alunos com risco de reprovaÃ§Ã£o.

Ferramentas usadas: SQL, Excel, Power BI


# CriaÃ§Ã£o de Macros, Refatoramento e Deplay em ProduÃ§Ã£o com DBT

ğŸ“š Preparaando a MÃ¡quina Cliente com DBT

Usaremos um script para criar uma imagem de container personalizada. Ele define um ambiente pronto para desenvolvimento e execuÃ§Ã£o de projetos dbt (Data Build Tool) com SQLite, dentro de um container.


ğŸ”§ Etapas detalhadas do que ele faz:


1. Escolha da base da imagem:

* A imagem comeÃ§a com uma versÃ£o enxuta do Python 3.11, chamada python:3.11-slim, que jÃ¡ vem com o interpretador Python instalado.


2. IdentificaÃ§Ã£o do mantenedor:

* Um rÃ³tulo (LABEL) Ã© adicionado para identificar quem mantÃ©m essa imagem. Neste caso, o nome informado Ã© "DSA" (possivelmente Data Science Academy ou um usuÃ¡rio).


3. InstalaÃ§Ã£o de ferramentas bÃ¡sicas do sistema operacional:

* Atualiza a lista de pacotes do sistema.

* Instala ferramentas Ãºteis como:

ğŸ”¹ build-essential: para compilar pacotes Python que tenham cÃ³digo nativo (C/C++).

ğŸ”¹ git: para controle de versÃ£o.

ğŸ”¹ vim e nano: editores de texto dentro do terminal.

ğŸ”¹ sqlite3: o sistema de banco de dados local que serÃ¡ usado com o dbt.

* ApÃ³s a instalaÃ§Ã£o, limpa os arquivos temporÃ¡rios para manter a imagem enxuta.


4. CriaÃ§Ã£o de diretÃ³rio e volume:

* Cria o diretÃ³rio /dsa, que servirÃ¡ como o local principal de trabalho no container.

* Define este diretÃ³rio como um volume Docker, o que significa que ele pode ser sincronizado com a mÃ¡quina host. Isso Ã© Ãºtil para salvar dados ou projetos mesmo apÃ³s o container ser parado.


5. DefiniÃ§Ã£o do diretÃ³rio de trabalho:

* Define /dsa como o diretÃ³rio onde todos os comandos futuros dentro do container serÃ£o executados. Ã‰ como fazer cd /dsa no terminal.


6. InstalaÃ§Ã£o do dbt com suporte ao SQLite:

* Instala o dbt-core, que Ã© o nÃºcleo da ferramenta dbt.

* Instala o dbt-sqlite, que Ã© o adaptador necessÃ¡rio para que o dbt possa se conectar a bancos de dados SQLite.


7. ExposiÃ§Ã£o de porta (opcional):

* A porta 8080 Ã© exposta para permitir que algum serviÃ§o futuro (como um dashboard ou servidor) possa ser acessado externamente se for configurado.


8. Comando padrÃ£o:

* Define o /bin/bash como o comando a ser executado quando o container iniciar. Isso significa que, ao rodar o container, o usuÃ¡rio serÃ¡ levado a um terminal bash para poder interagir diretamente com o ambiente.


![image](https://github.com/user-attachments/assets/305d17a7-c14f-477d-b223-145967006ef5)


ğŸ“š Criando o Projeto DBT e Configurando os targets

![image](https://github.com/user-attachments/assets/a8898a1e-abd4-4e93-97c9-2c063cf0ae2e)

* Vamos criar um ambiente com dev e prod usando SQLite. Criar modelos, rodar transformaÃ§Ãµes, aplicar testes e gerar documentaÃ§Ã£o.

Seguindo o paso a paso do projeto teremos esse resultado (paso a paso na paasta):

![image](https://github.com/user-attachments/assets/6ac5472e-f46a-48bc-917c-daed913c1a59)

Verificando o debug:

![image](https://github.com/user-attachments/assets/b47fbf1f-d5d4-45ab-b74a-434ff104136b)


ğŸ“š Deploy dos Modelos de Dados Iniciais

Vamos passar os Models que estou disponibilizando para a pasta que foi criada. Primeiro vamos passar o modelo de Venda e o de Cliente. ApÃ³s vamos para o Docker e executar o comando dbt run.

ğŸ” O que estÃ¡ acontecendo (CÃ§iente):

1. {{ config(materialized='view') }}

* Informa ao dbt que este modelo serÃ¡ materializado como uma view, ou seja:

    * O dbt criarÃ¡ uma view no banco de dados ao invÃ©s de uma tabela fÃ­sica.

    * A view sempre trarÃ¡ dados atualizados diretamente da tabela tb_clientes.

2. WITH clientes_base AS (...)

* Cria uma CTE (Common Table Expression) chamada clientes_base com todos os dados da tabela tb_clientes.

3. SELECT final:

* Retorna os campos cliente_id, nome, cidade e estado da CTE clientes_base.

ğŸ“Œ Resumo:

Esse modelo cria uma view no banco com os dados completos de clientes, extraÃ­dos diretamente de tb_clientes.


ğŸ” O que estÃ¡ acontecendo (Vendas):

1. {{ config(materialized='view') }}

* Novamente, dbt criarÃ¡ uma view em vez de uma tabela materializada.

2. CTE vendas_base

* Carrega os dados da tabela tb_vendas, mas filtra apenas as vendas com valor inferior a R$ 500.

3. SELECT final:

* Seleciona os campos principais de cada venda com valor menor que 500: venda_id, cliente_id, data_venda, valor.

ğŸ“Œ Resumo:

Esse modelo cria uma view com vendas de baixo valor (menos de R$ 500), Ãºtil para anÃ¡lises especÃ­ficas ou filtragem de dados antes de cÃ¡lculos posteriores.

Resultado da CriaÃ§Ã£o
![image](https://github.com/user-attachments/assets/4ef71638-f24d-48cf-bb34-3313e537b2b8)


ğŸ“š Deploy do Modelo Maart

Na pasta "models" vamos criar a pasta "mart" e passar os modelos paraa ele:

![image](https://github.com/user-attachments/assets/c4ba440d-c208-4b5c-8e16-d7121b812939)

![image](https://github.com/user-attachments/assets/c6fed001-1c1f-437c-b979-769919c5cd3f)
OBS:Teremos que mudar o nome conforme aparrece

ğŸ” Como resultado

Este modelo dbt:

Combina os dados dos modelos clientes e vendas usando o cliente_id.

Filtra os clientes apenas dos estados SP e RJ.

Calcula o total de vendas por cliente.

ğŸ“Œ Resultado final:

VocÃª terÃ¡ uma tabela (provavelmente uma view, dependendo da configuraÃ§Ã£o {{ config(...) }} no topo do arquivo) com a seguinte estrutura:

![image](https://github.com/user-attachments/assets/b5a594e2-336f-4add-ae66-412863cbdc45)


ğŸ“š ConstruÃ§Ã£o da Macro

Da mesma forma como fizemos com os models e os mart, vamos transferir asa macros para a pasta que foi criada. 

* E para que elas serrvem: 

Para reutilizar lÃ³gica SQL em mÃºltiplos modelos, promovendo refatoraÃ§Ã£o e padronizaÃ§Ã£o.

Onde uma calcula a mÃ©dia apenas das vendas com valor menor que 450.

ğŸ” ExplicaÃ§Ã£o passo a passo:

{{ valor }}: Ã© um argumento da macro â€” vocÃª passa o nome da coluna ao chamÃ¡-la (por exemplo, valor).

CASE WHEN {{ valor }} < 450 THEN {{ valor }} ELSE NULL END:
Essa expressÃ£o substitui valores maiores ou iguais a 450 por NULL, que sÃ£o ignorados pela funÃ§Ã£o AVG().

Resultado: uma mÃ©dia condicional, baseada apenas em valores abaixo de 450.

E a outra soma os valores de uma coluna. Ã‰ basicamente um atalho para SUM(...).

ğŸ” ExplicaÃ§Ã£o:

{{ valor }} Ã© o nome da coluna que vocÃª vai somar.

SUM({{ valor }}) executa a soma dos valores dessa coluna no SQL.


![image](https://github.com/user-attachments/assets/d91be7a5-4c68-435d-ac58-450289b43039)


âœ… ConclusÃ£o

Ao longo deste material, exploramos os principais fundamentos e prÃ¡ticas de transformaÃ§Ã£o de dados, um pilar essencial na engenharia de dados moderna. Desde a garantia da qualidade e padronizaÃ§Ã£o dos dados atÃ© a integraÃ§Ã£o, agregaÃ§Ã£o e enriquecimento das informaÃ§Ãµes, cada etapa do processo contribui diretamente para a criaÃ§Ã£o de pipelines mais eficientes, escalÃ¡veis e confiÃ¡veis.

Utilizando o dbt (Data Build Tool), vimos como Ã© possÃ­vel estruturar transformaÃ§Ãµes com clareza, versionamento e reprodutibilidade. Por meio de CTEs, modelos materializados como views, e a construÃ§Ã£o de marts analÃ­ticos, organizamos os dados de forma lÃ³gica e eficiente. AlÃ©m disso, introduzimos macros reutilizÃ¡veis, facilitando a padronizaÃ§Ã£o de cÃ¡lculos e promovendo a manutenÃ§Ã£o do cÃ³digo.

Na prÃ¡tica, construÃ­mos um ambiente controlado com SQLite dentro de um container Docker, onde criamos modelos de clientes e vendas, aplicamos filtros e junÃ§Ãµes, e produzimos uma visÃ£o analÃ­tica consolidada com foco em regiÃµes especÃ­ficas. TambÃ©m mostramos como estruturar o projeto dbt com separaÃ§Ã£o entre ambientes de desenvolvimento e produÃ§Ã£o.

Esse tipo de abordagem torna o dbt uma ferramenta extremamente poderosa para projetos de dados modernos, especialmente em contextos de ELT, onde a transformaÃ§Ã£o ocorre apÃ³s a carga dos dados. AlÃ©m disso, ao aplicar os conceitos aprendidos em setores como varejo, saÃºde, logÃ­stica e finanÃ§as, reforÃ§amos a aplicabilidade real e o impacto da transformaÃ§Ã£o de dados nas decisÃµes estratÃ©gicas das organizaÃ§Ãµes.

Por fim, com a adoÃ§Ã£o de boas prÃ¡ticas como modularizaÃ§Ã£o de modelos, uso de macros personalizadas, e organizaÃ§Ã£o por camadas (staging, marts, etc.), estamos construindo nÃ£o apenas transformaÃ§Ãµes, mas plataformas de dados robustas, auditÃ¡veis e escalÃ¡veis.

